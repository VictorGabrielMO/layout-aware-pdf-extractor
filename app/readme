## üß© Desafio de Extra√ß√£o de Informa√ß√µes de Documentos

Este projeto implementa uma **API de extra√ß√£o de informa√ß√µes de documentos PDF** utilizando **LLM (Large Language Models)**, com foco em **efici√™ncia e reuso de conhecimento** atrav√©s de uma **mem√≥ria de layout persistente** e **cache de resultados**.

---

### üöÄ Vis√£o Geral da Solu√ß√£o

O sistema √© composto por um pipeline modular que processa PDFs e aprende progressivamente o layout dos documentos para reduzir drasticamente o tempo de execu√ß√£o em execu√ß√µes subsequentes.  
A arquitetura foi desenhada para que o modelo de linguagem seja acionado **apenas quando estritamente necess√°rio**, com base em **heur√≠sticas estat√≠sticas** e **armazenamento incremental de padr√µes (regexes)**.

---

### ‚öôÔ∏è Pipeline de Processamento

A pipeline √© composta pelas seguintes etapas principais:

#### 1. **Extra√ß√£o de texto e blocos (PDFParser)**
- O PDF √© processado em duas representa√ß√µes:
  - Texto plano completo (`extract_plain_text`), usado para fingerprint e cache.
  - Blocos textuais estruturados (`extract_text_blocks`), contendo texto e coordenadas normalizadas (px, py).
- Essa granularidade permite an√°lises espaciais precisas no layout.

#### 2. **Pr√©-processamento dos blocos (Preprocessor)**
- Os blocos s√£o limpos e normalizados (remo√ß√£o de ru√≠do, quebras e padr√µes redundantes).
- A sa√≠da √© uma lista de blocos prontos para serem analisados pela heur√≠stica de layout.

#### 3. **Mem√≥ria de Layout (LayoutMemory)**
Essa √© a **camada central de intelig√™ncia** da solu√ß√£o.

- Cada campo de cada tipo de documento √© armazenado com:
  - As **coordenadas m√©dias (px, py)** em que o campo aparece.
  - As **vari√¢ncias acumuladas (M2_px, M2_py)**.
  - Um **regex aprendido** pelo LLM, usado para extra√ß√µes diretas futuras.
- Os valores s√£o atualizados incrementalmente com o **algoritmo de Welford**, o que garante m√©dias e vari√¢ncias corretas sem reprocessar o hist√≥rico.

##### üß† Heur√≠stica de Intervalo de Confian√ßa (CI)
Para cada campo, √© calculado um **intervalo de confian√ßa (IC)** das posi√ß√µes:

\[
IC_{px} = \bar{px} \pm z \cdot \frac{\sigma_{px}}{\sqrt{n}}
\]
\[
IC_{py} = \bar{py} \pm z \cdot \frac{\sigma_{py}}{\sqrt{n}}
\]

- Se o intervalo √© **estreito (alta confian√ßa)** e o n√∫mero de amostras √© suficiente, assume-se que o campo √© **posicionalmente est√°vel**.
- Assim, √© poss√≠vel identificar diretamente o bloco correspondente **sem consultar o LLM**.

Essa heur√≠stica reduz drasticamente o custo das infer√™ncias:
- Os primeiros documentos de cada tipo demandam chamadas ao LLM (pois √© necess√°rio aprender os regexes e coordenadas);
- As execu√ß√µes seguintes reutilizam o conhecimento armazenado, tornando o processo **quase instant√¢neo**.

##### üåê Signific√¢ncia e decis√£o de fallback
O sistema classifica cada campo como:
- `high` ‚Üí coordenadas altamente confi√°veis (dispensa LLM);
- `medium` ‚Üí coordenadas moderadamente est√°veis (uso h√≠brido);
- `low` ‚Üí inst√°vel, depende do LLM.

#### 4. **LLM Processor**
- Quando a mem√≥ria de layout n√£o √© suficiente, o pipeline constr√≥i um *prompt contextualizado* e envia ao LLM.
- O modelo retorna:
  - `valor` extra√≠do
  - `regex` usado para encontr√°-lo
  - `bloco` de origem
- O regex e posi√ß√£o s√£o armazenados na mem√≥ria para futuros usos.

#### 5. **Cache de resultados (document-level cache)**
Para acelerar ainda mais, h√° um **cache persistente por documento e schema**:
- √â gerado um *fingerprint SHA256* do texto e schema.
- Se um documento id√™ntico j√° foi processado, o resultado √© retornado diretamente sem nova an√°lise.

---

### üìâ Otimiza√ß√µes de Desempenho

| T√©cnica | Descri√ß√£o | Impacto |
|----------|------------|---------|
| **Mem√≥ria de Layout com IC** | Aprende posi√ß√µes m√©dias e varia√ß√£o dos campos. | Reduz consultas ao LLM conforme o uso aumenta. |
| **Armazenamento incremental (Welford)** | Atualiza estat√≠sticas sem reprocessar hist√≥rico. | Mant√©m desempenho est√°vel e preciso. |
| **Cache de documentos (SHA256)** | Retorna resultados instantaneamente para PDFs j√° processados. | Evita recomputa√ß√£o e chamadas √† API. |
| **LRU caching interno** | Minimiza acesso ao banco SQLite. | Diminui lat√™ncia de consultas repetidas. |

üí° **Tend√™ncia natural de desempenho:**  
As primeiras requisi√ß√µes de um tipo de documento ser√£o lentas (depend√™ncia do LLM), mas o sistema convergir√° rapidamente para tempo de execu√ß√£o muito baixo conforme acumula conhecimento.

---

### üß© Exemplo de Fluxo Simplificado

1. Recebe PDF de Nota Fiscal (`label="nota_fiscal"`).  
2. LayoutMemory ainda vazio ‚Üí tudo vai para o LLM.  
3. LLM retorna valores + regex + posi√ß√µes.  
4. Sistema atualiza mem√≥ria com m√©dia, vari√¢ncia e regex.  
5. Pr√≥ximos documentos similares:  
   - Blocos s√£o casados via IC e regex.  
   - Somente campos n√£o encontrados v√£o ao LLM.  

Resultado: **redu√ß√£o progressiva do custo por documento.**

---

### üß∞ Tecnologias Utilizadas

- **FastAPI** ‚Äî backend e endpoint `/extract`
- **SQLite** ‚Äî armazenamento leve e persistente da mem√≥ria de layout
- **OpenAI API** ‚Äî processamento de linguagem natural e aprendizado de padr√µes
- **Pydantic** ‚Äî valida√ß√£o de entrada e sa√≠da
- **Docker** ‚Äî empacotamento e execu√ß√£o isolada

---

### üìä Considera√ß√µes Finais

A principal proposta dessa solu√ß√£o √© transformar o processo de extra√ß√£o de dados via LLM ‚Äî tipicamente caro e lento ‚Äî em um **sistema de aprendizado cont√≠nuo de layout**, com:
- Redu√ß√£o adaptativa de custo;
- Autoaprendizado de padr√µes;
- Independ√™ncia crescente do modelo de linguagem.

Com o uso, o pipeline se comporta como um **extrator cognitivo especializado**, otimizando-se de forma aut√¥noma com base nas intera√ß√µes anteriores.
